{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSetPath = r\"..\\1_DataSets\\worldcities.csv\"\n",
    "\n",
    "dataset = pd.read_csv(dataSetPath)\n",
    "dataSetName = os.path.basename(dataSetPath)\n",
    "\n",
    "print(f\"Dataset Columns: {dataset.columns.to_list()}\")\n",
    "print(\"****************************\")\n",
    "print(f\"Dataset Shape: {dataset.shape}\")\n",
    "print(\"****************************\")\n",
    "\n",
    "totalNumberOfRowInActualDataset = len(dataset)\n",
    "print(f\"Total Rows in dataset File: {totalNumberOfRowInActualDataset}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-proccessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(inplace=True)\n",
    "print(f\"Dataset Shape after removing duplcates: {dataset.shape}\")\n",
    "print(\"****************************\")\n",
    "\n",
    "numberOfRowAfterRemovingDuplicates = len(dataset)\n",
    "print(f\"Remaining Rows in Dataset: {numberOfRowAfterRemovingDuplicates}\")\n",
    "\n",
    "print(\"****************************\")\n",
    "print(f\"Total Duplicates: {(totalNumberOfRowInActualDataset - numberOfRowAfterRemovingDuplicates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Handle missing values (remove rows with missing values)\n",
    "cleanedDataset = dataset.dropna()\n",
    "numberOfRowAfterRemovingNullValues = len(cleanedDataset)\n",
    "print(f\"Remaining Rows in Dataset: {numberOfRowAfterRemovingNullValues}\")\n",
    "\n",
    "print(\"****************************\")\n",
    "print(f\"Removed Number of rows containing Null Values: {( numberOfRowAfterRemovingDuplicates - numberOfRowAfterRemovingNullValues)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = cleanedDataset[cleanedDataset.columns.to_list()[-1]].unique()\n",
    "print(target_column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedDataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Mean Clustering, Calculating Centroids Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant features: latitude (lat) and longitude (lng)\n",
    "coordinates = cleanedDataset[['lat', 'lng']].values\n",
    "\n",
    "# Define the number of clusters (k)\n",
    "k = 5\n",
    "# K-Means Clustering Process\n",
    "max_iterations = 30\n",
    "\n",
    "\n",
    "output_dir = f\"kmeans_steps_{dataSetName}_Features_lat_lng\"  # Directory to save the plots\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize random centroids (pick k random points from the data)\n",
    "np.random.seed(42)\n",
    "centroids = coordinates[np.random.choice(coordinates.shape[0], k, replace=False)]\n",
    "\n",
    "# Function to plot clusters and centroids\n",
    "def plot_clusters(coordinates, labels, centroids, iteration):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "    \n",
    "    # Plot each cluster\n",
    "    for cluster in range(k):\n",
    "        cluster_points = coordinates[labels == cluster]\n",
    "        plt.scatter(cluster_points[:, 1], cluster_points[:, 0], s=100, color=colors[cluster], label=f'Cluster {cluster + 1}')\n",
    "    \n",
    "    # Plot centroids\n",
    "    plt.scatter(centroids[:, 1], centroids[:, 0], c='black', marker='x', s=200, label='Centroids')\n",
    "    plt.title(f'K-Means Clustering - Iteration {iteration}')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # Save the plot\n",
    "    file_name = os.path.join(output_dir, f\"iteration_{iteration + 1}.png\")\n",
    "    plt.savefig(file_name)\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "\n",
    "for iteration in range(1, max_iterations + 1):\n",
    "    # Assign clusters based on the closest centroid\n",
    "    labels = pairwise_distances_argmin(coordinates, centroids)\n",
    "    \n",
    "    # Plot the current state of clusters and centroids\n",
    "    plot_clusters(coordinates, labels, centroids, iteration)\n",
    "    \n",
    "    # Recalculate centroids as the mean of assigned points\n",
    "    new_centroids = np.array([coordinates[labels == cluster].mean(axis=0) for cluster in range(k)])\n",
    "    \n",
    "    # Check for convergence (if centroids do not change)\n",
    "    if np.all(centroids == new_centroids):\n",
    "        print(f\"Convergence reached at iteration {iteration}\")\n",
    "        break\n",
    "    \n",
    "    centroids = new_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
