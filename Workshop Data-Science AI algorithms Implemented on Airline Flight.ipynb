{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as mplot\n",
    "from matplotlib.colors import ListedColormap\n",
    "import os \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.datasets import load_files \n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score,  precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    " \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, HistGradientBoostingClassifier, StackingClassifier, VotingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier , RidgeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis  \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "#import xgboost as xgb\n",
    "#from catboost import CatBoostClassifier\n",
    "#import lightgbm as lgb  \n",
    "\n",
    "\n",
    "#import shap\n",
    "#import lime\n",
    "#from lime import lime_tabular\n",
    "import random\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of fileData: (300153, 12)\n",
      "Column Headings: Index(['index', 'airline', 'flight', 'source_city', 'departure_time', 'stops',\n",
      "       'arrival_time', 'destination_city', 'class', 'duration', 'days_left',\n",
      "       'price'],\n",
      "      dtype='object')\n",
      "Number of Records: 300153\n",
      "\n",
      "Number of Missing Values: 0\n",
      "Number of duplicate records removed: 0\n",
      "Shape of fileData: (300153, 12)\n",
      "Shape of fileData End: (300153, 12)\n",
      "\n",
      "\n",
      "columns of x:: 11 \n",
      "\n",
      " and features of X: Index(['index', 'airline', 'flight', 'source_city', 'departure_time', 'stops',\n",
      "       'arrival_time', 'destination_city', 'class', 'duration', 'days_left'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dataSetIndex = 8\n",
    "needToMakePictureOfTrees = 0\n",
    "''' ---------------------------------------------------------- '''\n",
    "dataSetFilePath = \"\"\n",
    "dataSetName = \"\"\n",
    "dataSetResultDirectory = \"./\"\n",
    "\n",
    "dataSetFilePath = r\".\\1_DataSets\\airlines_flights_data.csv\"\n",
    "dataSetName = \"AirLine_Flights\"\n",
    "\n",
    "fileData = pd.read_csv(dataSetFilePath)\n",
    "\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))\n",
    "print(\"Column Headings: {}\".format(fileData.__dataframe__().column_names()))\n",
    "print(\"Number of Records: {}\".format(fileData.__dataframe__().num_rows()))\n",
    "\n",
    "\n",
    "missingValues = fileData.isnull().any().sum()\n",
    "print(f\"\\nNumber of Missing Values: {missingValues}\")\n",
    "\n",
    "num_rows_before = fileData.shape[0]\n",
    "# Remove duplicate records based on all columns\n",
    "fileData.drop_duplicates(inplace=True)\n",
    "# Check the number of rows after removing duplicates\n",
    "num_rows_after = fileData.shape[0]\n",
    "# Print the number of duplicate records removed\n",
    "num_duplicates_removed = num_rows_before - num_rows_after\n",
    "print(f\"Number of duplicate records removed: {num_duplicates_removed}\")\n",
    " \n",
    " # Preprocess Steps from the ChatGPT\n",
    "# 1. Handling Missing Values:\n",
    "fileData = fileData.dropna()\n",
    "print(\"Shape of fileData: {}\".format(fileData.shape))              \n",
    "#fileData.replace({'?': np.nan}).dropna().astype(float)\n",
    "#fileData = fileData.fillna(0) \n",
    "\n",
    "fileData = fileData.fillna(0) \n",
    "\n",
    "print(\"Shape of fileData End: {}\".format(fileData.shape))\n",
    "\n",
    "\n",
    "\n",
    "finalResultTable = [ ['Index', 'Method', 'Accuracy %','Recall %','Precision %','F1 Score','AUC'], ] \n",
    "\n",
    "\n",
    "dataSetResultDirectory += (\"Results_\" + dataSetName)\n",
    "dataSetResultDirectory += \"/\"\n",
    "if not os.path.isdir(dataSetResultDirectory):\n",
    "    os.makedirs(dataSetResultDirectory)\n",
    " \n",
    "\n",
    "X = fileData.drop(fileData.__dataframe__().column_names()[-1], axis=1)  # Features\n",
    "Y = fileData[fileData.__dataframe__().column_names()[-1]]  # Labels\n",
    "\n",
    "columns = fileData.__dataframe__().column_names() \n",
    "totalRecords = (fileData.__dataframe__().num_rows())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"columns of x:: {} \\n\\n and features of X: {}\".format(len(X.columns), X.columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8157</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AirAsia</td>\n",
       "      <td>I5-764</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-995</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-963</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-945</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-927</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1</td>\n",
       "      <td>6060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-951</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>zero</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>6060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   airline   flight source_city departure_time stops   arrival_time  \\\n",
       "0      0  SpiceJet  SG-8709       Delhi        Evening  zero          Night   \n",
       "1      1  SpiceJet  SG-8157       Delhi  Early_Morning  zero        Morning   \n",
       "2      2   AirAsia   I5-764       Delhi  Early_Morning  zero  Early_Morning   \n",
       "3      3   Vistara   UK-995       Delhi        Morning  zero      Afternoon   \n",
       "4      4   Vistara   UK-963       Delhi        Morning  zero        Morning   \n",
       "5      5   Vistara   UK-945       Delhi        Morning  zero      Afternoon   \n",
       "6      6   Vistara   UK-927       Delhi        Morning  zero        Morning   \n",
       "7      7   Vistara   UK-951       Delhi      Afternoon  zero        Evening   \n",
       "\n",
       "  destination_city    class  duration  days_left  price  \n",
       "0           Mumbai  Economy      2.17          1   5953  \n",
       "1           Mumbai  Economy      2.33          1   5953  \n",
       "2           Mumbai  Economy      2.17          1   5956  \n",
       "3           Mumbai  Economy      2.25          1   5955  \n",
       "4           Mumbai  Economy      2.33          1   5955  \n",
       "5           Mumbai  Economy      2.33          1   5955  \n",
       "6           Mumbai  Economy      2.08          1   6060  \n",
       "7           Mumbai  Economy      2.17          1   6060  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileData.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colli in range(len(fileData.__dataframe__().column_names())):\n",
    "    unique_values = fileData[fileData.__dataframe__().column_names()[colli]].unique()\n",
    "    value_counts = fileData[fileData.__dataframe__().column_names()[colli]].value_counts()\n",
    "    '''\n",
    "    if(len(unique_values)< 10):\n",
    "        print(\"\\n\\n{} -> {} : Unique:{}, ValueCount:{}\".format(colli, fileData.__dataframe__().column_names()[colli], unique_values, value_counts))\n",
    "    else:\n",
    "        print(\"\\n\\n{} -> {} : Unique:{}, ValueCount:{}\".format(colli, fileData.__dataframe__().column_names()[colli], len(unique_values), value_counts))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResultTable = [ ['Index', 'Method', 'Accuracy %','Recall %','Precision %','F1 Score', 'AUC'], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1408</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1387</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1213</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1559</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1549</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  airline  flight  source_city  departure_time  stops  arrival_time  \\\n",
       "0      0        4    1408            2               2      2             5   \n",
       "1      1        4    1387            2               1      2             4   \n",
       "2      2        1    1213            2               1      2             1   \n",
       "3      3        5    1559            2               4      2             0   \n",
       "4      4        5    1549            2               4      2             4   \n",
       "\n",
       "   destination_city  class  duration  days_left  price  \n",
       "0                 5      1      2.17          1   5953  \n",
       "1                 5      1      2.33          1   5953  \n",
       "2                 5      1      2.17          1   5956  \n",
       "3                 5      1      2.25          1   5955  \n",
       "4                 5      1      2.33          1   5955  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncodingAlgorithmFromScienceKit = LabelEncoder()\n",
    "\n",
    "for col in fileData.select_dtypes(include=['object', 'category', 'bool', 'datetime']).columns:\n",
    "    fileData[col] = fileData[col].str.lower()\n",
    "    fileData[col] = fileData[col].str.strip()\n",
    "    fileData[col] = labelEncodingAlgorithmFromScienceKit.fit_transform(fileData[col])\n",
    " \n",
    "\n",
    "fileData.shape\n",
    "\n",
    "fileData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1408</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1387</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1213</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1559</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1549</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline  flight  source_city  departure_time  stops  arrival_time  \\\n",
       "0        4    1408            2               2      2             5   \n",
       "1        4    1387            2               1      2             4   \n",
       "2        1    1213            2               1      2             1   \n",
       "3        5    1559            2               4      2             0   \n",
       "4        5    1549            2               4      2             4   \n",
       "\n",
       "   destination_city  class  duration  days_left  price  \n",
       "0                 5      1      2.17          1   5953  \n",
       "1                 5      1      2.33          1   5953  \n",
       "2                 5      1      2.17          1   5956  \n",
       "3                 5      1      2.25          1   5955  \n",
       "4                 5      1      2.33          1   5955  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileData = fileData.drop(columns=['index'])\n",
    "fileData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "columns of x:: 10 \n",
      "\n",
      " and features of X: Index(['airline', 'flight', 'source_city', 'departure_time', 'stops',\n",
      "       'arrival_time', 'destination_city', 'class', 'duration', 'days_left'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = fileData.drop(fileData.__dataframe__().column_names()[-1], axis=1)  # Features\n",
    "Y = fileData[fileData.__dataframe__().column_names()[-1]]  # Labels\n",
    "\n",
    "columns = fileData.__dataframe__().column_names() \n",
    "totalRecords = (fileData.__dataframe__().num_rows())\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"columns of x:: {} \\n\\n and features of X: {}\".format(len(X.columns), X.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCorrelationPic(correlationMatrix, numberOfTopFeatures, targetColumnName):     \n",
    "    correlation_values = correlationMatrix.abs()\n",
    "    sorted_correlation = correlation_values.unstack().sort_values(ascending=False)\n",
    "    sorted_correlation = sorted_correlation[sorted_correlation != 1.0]\n",
    "\n",
    "    num_features = numberOfTopFeatures  # Number of top features to display\n",
    "    top_features = sorted_correlation.head(num_features)\n",
    "    #print(\"Top\", num_features, \"features based on correlation:\")\n",
    "    #print(top_features)\n",
    " \n",
    "    top_features = correlationMatrix.abs().nlargest(numberOfTopFeatures, targetColumnName)[targetColumnName].index\n",
    "    top_correlation_matrix = correlationMatrix.loc[top_features, top_features]\n",
    "\n",
    "    mplot.figure(figsize=(10, 8))\n",
    "    sns.heatmap(top_correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    # Set the title of the plot\n",
    "    mplot.title('Correlation Heatmap ({})'.format(dataSetName)  ,fontsize=16, fontweight='bold')\n",
    "    \n",
    "    picturePath = \"{}0.1_Correlation_Matrix_DateSetName_{}.png\".format(dataSetResultDirectory, dataSetName)\n",
    "    \n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "def plot_classification_report(title, dataSetName, y_tru, y_prd, figsize=(6, 6), ax=None):\n",
    "    #mplot.figure(figsize=figsize)\n",
    "    xticks = ['precision', 'recall', 'f1-score', 'support']\n",
    "    yticks = ['Healthy', 'Heart Disease']\n",
    "    rep = np.array( precision_recall_fscore_support(y_tru, y_prd) ).T\n",
    "    rep[0][0] *= 100.0\n",
    "    rep[0][1] *= 100.0\n",
    "    rep[0][2] *= 100.0\n",
    "    rep[1][0] *= 100.0\n",
    "    rep[1][1] *= 100.0\n",
    "    rep[1][2] *= 100.0\n",
    "    \n",
    "    ax = sns.heatmap(rep, annot=True, cmap='Blues', cbar=False, xticklabels=xticks, yticklabels=yticks)\n",
    "    ax.set_title(\"Classification Report {} Model\\n\\n\".format(title) ,fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('\\nDataset:{}'.format(dataSetName))\n",
    "    ax.xaxis.set_ticklabels(xticks)\n",
    "    ax.set_ylabel('Classes')\n",
    "    ax.yaxis.set_ticklabels(yticks)\n",
    "    \n",
    "    picturePath = \"{}ClassificationReport_{}_{}.png\".format(dataSetResultDirectory, title, dataSetName) \n",
    "    mplot.savefig(picturePath, dpi=300, bbox_inches='tight')\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.close()\n",
    "def makeConfusionMatrixPic(fileID, method, dataSet, classifierObj , X_test, y_test, predicted_Y):\n",
    "    display = ConfusionMatrixDisplay.from_predictions(y_test,predicted_Y, cmap=mplot.cm.Blues) #, normalize=\"true\"\n",
    "    \n",
    "    display.ax_.set_title(\"Confusion Matrix ({})\".format(method) ,fontsize=16, fontweight='bold')\n",
    "    display.ax_.set_xlabel('\\nPredicted Values')\n",
    "    display.ax_.set_ylabel('Actual Values ') \n",
    " \n",
    "    accuracyValue = (accuracy_score(y_test, predicted_Y)*100.0) \n",
    "    recallValue = (recall_score(y_test, predicted_Y, average='weighted') * 100.0)\n",
    "    precisionValue = (precision_score(y_test, predicted_Y) * 100.0) \n",
    "    f1Score = (f1_score(y_test, predicted_Y, average='weighted') * 100.0)\n",
    "\n",
    " \n",
    "    singleRowInTable = [] \n",
    "    singleRowInTable.append(fileID)\n",
    "    singleRowInTable.append(method)\n",
    "    singleRowInTable.append(\"{:.2f}\".format(accuracyValue) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(recallValue) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(precisionValue) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(f1Score) )\n",
    "    singleRowInTable.append(\"-\")\n",
    "\n",
    "    finalResultTable.append((singleRowInTable) )\n",
    "\n",
    "\n",
    "    accuracyString =\"Accuracy : {:.2f} %\".format( accuracyValue) \n",
    "    recallString =  'Recall : {:.2f} %'.format(recallValue)\n",
    "    precisionString = 'Precision : {:.2f} %'.format(precisionValue) \n",
    "    precisionString = 'Precision : {:.2f} %'.format(precisionValue) \n",
    "    f1String = 'F1 Score : {:.2f} %'.format(f1Score) \n",
    "    dataSetString = \"Dataset: {}\".format(dataSet)\n",
    "    \n",
    "    numberOfTrainingRecords = \"No of Training Records: {}  {:.2f} %\".format(len(X_train), ((len(X_train)/totalRecords) * 100.0))\n",
    "    numberOfTestingRecords = \"No of Testing Records: {}  {:.2f} %\".format(len(X_test), ((len(X_test)/totalRecords) * 100.0))\n",
    "\n",
    "\n",
    "    display.figure_.text(0.010, -0.05,  accuracyString, horizontalalignment='left', wrap=False , fontsize=12 )  \n",
    "    display.figure_.text(0.010, -0.09,  recallString, horizontalalignment='left', wrap=False , fontsize=12 )      \n",
    "    display.figure_.text(0.010, -0.13,  precisionString, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    display.figure_.text(0.010, -0.17,  f1String, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    display.figure_.text(0.010, -0.21,  dataSetString, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    #display.figure_.text(0.010, -0.25,  numberOfTrainingRecords, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    #display.figure_.text(0.010, -0.29,  numberOfTestingRecords, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    \n",
    "    '''\n",
    "    if(classifierObj.n_features_in_ > 10):\n",
    "        featureListString = 'Total Features: {}'.format(classifierObj.n_features_in_) \n",
    "    else:\n",
    "        featureListString = 'Features: {}'.format(classifierObj.feature_names_in_) \n",
    "    display.figure_.text(0.010, -0.28,  featureListString, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    '''\n",
    "    \n",
    "    picturePath = \"{}{}.Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, fileID, method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #print(\"{} Confusion Matrix saved:: path: {}\".format(method, picturePath))\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "\n",
    "\n",
    "def makeConfusionMatrixPicWithProbibality(fileID, method, dataSet, classifierObj , X_test, y_test, predicted_Y):\n",
    "    display = ConfusionMatrixDisplay.from_predictions(y_test,predicted_Y, cmap=mplot.cm.Blues) #, normalize=\"true\"\n",
    "    \n",
    "    display.ax_.set_title(\"Confusion Matrix ({})\".format(method) ,fontsize=16, fontweight='bold')\n",
    "    display.ax_.set_xlabel('\\nPredicted Values')\n",
    "    display.ax_.set_ylabel('Actual Values ') \n",
    "\n",
    "    predicted_Proba = classifierObj.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicted_Proba)\n",
    "    roc_auc = auc(fpr, tpr) \n",
    "\n",
    "    accuracyValue = (accuracy_score(y_test, predicted_Y)*100.0) \n",
    "    recallValue = (recall_score(y_test, predicted_Y, average='weighted') * 100.0)\n",
    "    precisionValue = (precision_score(y_test, predicted_Y) * 100.0) \n",
    "    f1Score = (f1_score(y_test, predicted_Y, average='weighted') * 100.0)\n",
    "\n",
    " \n",
    "    singleRowInTable = [] \n",
    "    singleRowInTable.append(fileID)\n",
    "    singleRowInTable.append(method)\n",
    "    singleRowInTable.append(\"{:.2f}\".format(accuracyValue) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(recallValue) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(precisionValue) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(f1Score) )\n",
    "    singleRowInTable.append(\"{:.2f}\".format(roc_auc) )\n",
    "\n",
    "    finalResultTable.append((singleRowInTable) )\n",
    "\n",
    "\n",
    "    accuracyString =\"Accuracy : {:.2f} %\".format( accuracyValue) \n",
    "    recallString =  'Recall : {:.2f} %'.format(recallValue)\n",
    "    precisionString = 'Precision : {:.2f} %'.format(precisionValue) \n",
    "    precisionString = 'Precision : {:.2f} %'.format(precisionValue) \n",
    "    f1String = 'F1 Score : {:.2f} %'.format(f1Score) \n",
    "    dataSetString = \"Dataset: {}\".format(dataSet)\n",
    "    \n",
    "    numberOfTrainingRecords = \"No of Training Records: {}  {:.2f} %\".format(len(X_train), ((len(X_train)/totalRecords) * 100.0))\n",
    "    numberOfTestingRecords = \"No of Testing Records: {}  {:.2f} %\".format(len(X_test), ((len(X_test)/totalRecords) * 100.0))\n",
    "\n",
    "\n",
    "    display.figure_.text(0.010, -0.05,  accuracyString, horizontalalignment='left', wrap=False , fontsize=12 )  \n",
    "    display.figure_.text(0.010, -0.09,  recallString, horizontalalignment='left', wrap=False , fontsize=12 )      \n",
    "    display.figure_.text(0.010, -0.13,  precisionString, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    display.figure_.text(0.010, -0.17,  f1String, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    display.figure_.text(0.010, -0.21,  dataSetString, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    #display.figure_.text(0.010, -0.25,  numberOfTrainingRecords, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    #display.figure_.text(0.010, -0.29,  numberOfTestingRecords, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    \n",
    "    '''\n",
    "    if(classifierObj.n_features_in_ > 10):\n",
    "        featureListString = 'Total Features: {}'.format(classifierObj.n_features_in_) \n",
    "    else:\n",
    "        featureListString = 'Features: {}'.format(classifierObj.feature_names_in_) \n",
    "    display.figure_.text(0.010, -0.28,  featureListString, horizontalalignment='left', wrap=False , fontsize=12 ) \n",
    "    '''\n",
    "    \n",
    "    picturePath = \"{}{}.Confusion_Matrix_{}_{}.png\".format(dataSetResultDirectory, fileID, method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    #print(\"{} Confusion Matrix saved:: path: {}\".format(method, picturePath))\n",
    "    #os.startfile(picturePath)\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "    \n",
    " \n",
    "    mplot.figure(figsize=(8, 6))\n",
    "    mplot.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    mplot.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    mplot.xlim([0.0, 1.0])\n",
    "    mplot.ylim([0.0, 1.05])\n",
    "    mplot.xlabel('False Positive Rate (FPR)')\n",
    "    mplot.ylabel('True Positive Rate (TPR)')\n",
    "    mplot.title('(ROC) Curve {} ({})'.format(method, dataSet))\n",
    "    mplot.legend(loc='lower right')\n",
    "    picturePath = \"{}{}.ROC_{}_{}.png\".format(dataSetResultDirectory, fileID, method, dataSetName)\n",
    "    mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "    mplot.show()\n",
    "    mplot.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_regression_model(fileID, method, dataSet, model, X_test, y_test, y_pred):\n",
    "    # Compute regression metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Store results in table\n",
    "    singleRowInTable = [\n",
    "        fileID,\n",
    "        method,\n",
    "        f\"{mae:.2f}\",\n",
    "        f\"{mse:.2f}\",\n",
    "        f\"{rmse:.2f}\",\n",
    "        f\"{r2:.2f}\"\n",
    "    ]\n",
    "    finalResultTable.append(singleRowInTable)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.2f}\")\n",
    "\n",
    "\n",
    "    # Scatter plot of predicted vs actual\n",
    "    mplot.figure(figsize=(8, 6))\n",
    "    mplot.scatter(y_test, y_pred, alpha=0.6, color=\"blue\")\n",
    "    mplot.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')  # Perfect prediction line\n",
    "    mplot.xlabel(\"Actual Values\")\n",
    "    mplot.ylabel(\"Predicted Values\")\n",
    "    mplot.title(f\"Predicted vs Actual - {method}\")\n",
    "    mplot.grid(True)\n",
    "    \n",
    "\n",
    "    picturePath = f\"{dataSetResultDirectory}{fileID}_Predicted_vs_Actual_{method}_{dataSetName}.png\"\n",
    "    mplot.savefig(picturePath, dpi=300, bbox_inches='tight')\n",
    "    mplot.show()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix \n",
    "correlation_matrix = fileData.corr()\n",
    "#makeCorrelationPic(correlation_matrix, 15, 'CoronaryHeartDisease') \n",
    "\n",
    "makeCorrelationPic(correlation_matrix, 9, fileData.__dataframe__().column_names()[-1] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300153, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[0:2000]\n",
    "Y = Y[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of fileData: {} , target Len:{}\".format(fileData.shape, len(Y)))\n",
    "print(\"X: {} , Y:{}\".format(X.shape, Y.shape))\n",
    "#print(\"\\n\\nX: head:: \\n{}\".format(X.head()))\n",
    "#print(\"\\n\\nY: head::\\n {}\".format(Y.head()))\n",
    "\n",
    "print(\"Target Column Name:: {} \\n\".format(fileData.__dataframe__().column_names()[-1]))\n",
    " \n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    " \n",
    "\n",
    "print(\"\\n X Train: Shape:: {}\".format(X_train.shape))\n",
    "print(\" X Test: Shape:: {}\".format(X_test.shape)) \n",
    "print(\"\\n X Train: Shape::\\n {}\".format(X_train.shape))\n",
    "print(\"\\n X Train: head::\\n {}\".format(X_train.columns))\n",
    "print(\"\\n X Test: head:: \\n{}\".format(X_test.columns))\n",
    "print(\"\\n Y Train: shape::\\n {}\".format(y_train.shape)) \n",
    "print(\"\\n Y Test: shape::\\n {}\".format(y_test.shape))  \n",
    "#print(\"\\n X Train: Info::\\n {}\".format(X_train.info())) \n",
    "\n",
    "instance = np.array(X_test)  # Example: explaining the first instance in the dataset\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableAImodelResultIndex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1905.17\n",
      "Mean Squared Error: 13300387.38\n",
      "Root Mean Squared Error: 3646.97\n",
      "R² Score: 0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mubi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m predicted_DT \u001b[38;5;241m=\u001b[39m classifierDT\u001b[38;5;241m.\u001b[39mpredict(X_test) \n\u001b[0;32m      6\u001b[0m methodName \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecisionTree\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m----> 7\u001b[0m \u001b[43mevaluate_regression_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtableAImodelResultIndex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethodName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataSetName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifierDT\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_DT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Calculate the accuracy of the classifier\u001b[39;00m\n\u001b[0;32m     11\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, predicted_DT)\n",
      "Cell \u001b[1;32mIn[21], line 216\u001b[0m, in \u001b[0;36mevaluate_regression_model\u001b[1;34m(fileID, method, dataSet, model, X_test, y_test, y_pred)\u001b[0m\n\u001b[0;32m    214\u001b[0m accuracyValue \u001b[38;5;241m=\u001b[39m (accuracy_score(y_test, y_pred)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100.0\u001b[39m) \n\u001b[0;32m    215\u001b[0m recallValue \u001b[38;5;241m=\u001b[39m (recall_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m)\n\u001b[1;32m--> 216\u001b[0m precisionValue \u001b[38;5;241m=\u001b[39m (\u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m) \n\u001b[0;32m    217\u001b[0m f1Score \u001b[38;5;241m=\u001b[39m (f1_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100.0\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# Scatter plot of predicted vs actual\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mubi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mubi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2247\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   2079\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   2080\u001b[0m     {\n\u001b[0;32m   2081\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2106\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2107\u001b[0m ):\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   2109\u001b[0m \n\u001b[0;32m   2110\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   2246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2247\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2252\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2254\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\mubi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mubi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1830\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \n\u001b[0;32m   1663\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m _check_zero_division(zero_division)\n\u001b[1;32m-> 1830\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1832\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1833\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mubi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1613\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1611\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1612\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1613\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1614\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1615\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1616\u001b[0m         )\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1618\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1619\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1620\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1623\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1624\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "#2.     Decision Trees\n",
    "classifierDT = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=8,  random_state=18) \n",
    "classifierDT.fit(X_train, y_train) \n",
    "predicted_DT = classifierDT.predict(X_test) \n",
    "\n",
    "methodName = \"DecisionTree\" \n",
    "evaluate_regression_model(tableAImodelResultIndex, methodName, dataSetName, classifierDT , X_test, y_test, predicted_DT)\n",
    "\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, predicted_DT)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.     Decision Trees\n",
    "classifierDT = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", max_depth=8,  random_state=18) \n",
    "classifierDT.fit(X_train_scaled, y_train) \n",
    "predicted_DT = classifierDT.predict(X_test_scaled) \n",
    "\n",
    "methodName = \"DecisionTree\" \n",
    "makeConfusionMatrixPicWithProbibality(tableAImodelResultIndex, methodName, dataSetName, classifierDT , X_test, y_test, predicted_DT)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, predicted_DT)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.     Random Forests\n",
    "classifierRF = RandomForestClassifier(n_estimators=80, criterion=\"log_loss\", max_depth=8, max_features=15,n_jobs=-1, oob_score=True, bootstrap=True, random_state = 18)\n",
    "classifierRF.fit(X_train, y_train)\n",
    "y_PredictionRF = classifierRF.predict(X_test)\n",
    "\n",
    "methodName = f\"Random Forest ({classifierRF.estimator_})\" \n",
    "#plot_classification_report(methodName, dataSetName, y_test, y_PredictionRF)  \n",
    "makeConfusionMatrixPicWithProbibality(tableAImodelResultIndex, methodName, dataSetName, classifierRF , X_test, y_test, y_PredictionRF)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.     Support Vector Machines (SVM)\n",
    "#classifierSVM = SVC(C=33, kernel=\"poly\") \n",
    "classifierSVM = SVC() \n",
    "classifierSVM.fit(X_train, y_train)\n",
    "y_PredictionSVM = classifierSVM.predict(X_test)\n",
    "\n",
    "methodName = \"Support Vector Machine\"\n",
    "makeConfusionMatrixPic(tableAImodelResultIndex, methodName, dataSetName, classifierSVM , X_test, y_test, y_PredictionSVM)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.     K-Nearest Neighbors (KNN)\n",
    "classifierKNN = KNN(n_neighbors=50, weights='uniform', )\n",
    "classifierKNN.fit(X_train, y_train)\n",
    "y_PredictionKNN = classifierKNN.predict(X_test)\n",
    "\n",
    "methodName = f\"K Nearest Neighbour\"\n",
    "makeConfusionMatrixPicWithProbibality(tableAImodelResultIndex, methodName, dataSetName, classifierKNN , X_test, y_test, y_PredictionKNN)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.     Naive Bayes (with appropriate modifications for numerical data, such as Gaussian Naive Bayes)\n",
    "classifierNB = GaussianNB(var_smoothing=0.00001 )\n",
    "classifierNB.fit(X_train, y_train)\n",
    "predicted_NB = classifierNB.predict(X_test)\n",
    "\n",
    "methodName = \"Naive Bayes\" \n",
    "makeConfusionMatrixPicWithProbibality(tableAImodelResultIndex, methodName, dataSetName, classifierNB , X_test, y_test, predicted_NB)\n",
    "tableAImodelResultIndex = tableAImodelResultIndex +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of rows in the table (excluding the header)\n",
    "num_rows = len(finalResultTable) - 1\n",
    "print(\"total Rows: {} -> Cols: {}\".format(len(finalResultTable), len(finalResultTable[0])))\n",
    "# Calculate the desired figure size based on the number of rows\n",
    "fig_width = 6  # Set the desired width of the figure\n",
    "fig_height = num_rows * 0.5  # Adjust the scaling factor to control the height\n",
    "\n",
    "fig, ax = mplot.subplots(figsize=(fig_width, fig_height)) \n",
    "table = mplot.table(cellText=finalResultTable, loc='center') \n",
    "\n",
    "table.auto_set_column_width(col=list(range(len(finalResultTable[0]))))\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12) \n",
    "table.scale(2.0, 2.0) \n",
    "\n",
    "dataSetString = \"Dataset:  {}, Total Records: {}, No. Features: {}\".format(dataSetName, X.__dataframe__().num_rows(), X.__dataframe__().num_columns())\n",
    "target =\"Target Column Name: {} , No of Classes: {}\".format(columns[-1], len(fileData[columns[-1]].value_counts()))\n",
    "distributionOfTargetClassA = \"No of Training Records: {}\".format(len(X_train))\n",
    " \n",
    "positiveClass =  0\n",
    "negativeClass = 0\n",
    "for i in y_train:\n",
    "    if(i == 0):\n",
    "        negativeClass += 1\n",
    "    if(i == 1):\n",
    "        positiveClass += 1\n",
    "classBrecords = \"Healthy Persons in training data: {}       {:.1f} %\".format(negativeClass, ((positiveClass/len(y_train)) * 100.0))\n",
    "classArecords = \"Non-Healthy Persons in training data: {}       {:.1f} %\".format(positiveClass, ((positiveClass/len(y_train)) * 100.0))\n",
    "\n",
    "\n",
    "\n",
    "positiveClassTest =  0\n",
    "negativeClassTest = 0\n",
    "for i in y_test:\n",
    "    if(i == 0):\n",
    "        negativeClassTest += 1\n",
    "    if(i == 1):\n",
    "        positiveClassTest += 1\n",
    "classBrecordsTest = \"Healthy Persons in test data: {}       {:.1f} %\".format(negativeClassTest, ((negativeClassTest/len(y_test)) * 100.0))\n",
    "classArecordsTest = \"Non-Healthy Persons in test data: {}       {:.1f} %\".format(positiveClassTest, ((positiveClassTest/len(y_test)) * 100.0))\n",
    "\n",
    "distributionOfTargetClassB = \"No of Testing Records: {} \".format(len(X_test))\n",
    "\n",
    "fig.text(-0.1, -0.10,  dataSetString, horizontalalignment='left', wrap=False , fontsize=12 )  \n",
    "fig.text(-0.1, -0.18,  target, horizontalalignment='left', wrap=False  , fontsize=12 )   \n",
    "fig.text(-0.1, -0.26,  distributionOfTargetClassA, horizontalalignment='left', wrap=False , fontsize=12  )   \n",
    "fig.text(-0.1, -0.34,  classBrecords, horizontalalignment='left', wrap=False , fontsize=12  )   \n",
    "fig.text(-0.1, -0.42,  classArecords, horizontalalignment='left', wrap=False , fontsize=12  )   \n",
    "\n",
    "fig.text(-0.1, -0.54,  distributionOfTargetClassB, horizontalalignment='left', wrap=False  , fontsize=12 )  \n",
    "fig.text(-0.1, -0.62,  classBrecordsTest, horizontalalignment='left', wrap=False , fontsize=12  )   \n",
    "fig.text(-0.1, -0.70,  classArecordsTest, horizontalalignment='left', wrap=False , fontsize=12  )   \n",
    " \n",
    "mplot.axis('off')\n",
    "mplot.title(f'Final Result Table ({dataSetName})' , fontsize=16, fontweight='bold') \n",
    "picturePath = \"{}99.Final_Result_Table_{}.png\".format(dataSetResultDirectory, dataSetName)\n",
    "mplot.savefig(picturePath,  dpi=300, bbox_inches='tight')\n",
    "#mplot.savefig(picturePath,  dpi=300)\n",
    "mplot.show()\n",
    "mplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
